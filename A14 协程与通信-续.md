## 第十四章 协程与通信

### 5 通道、超时和计时器（Ticker）

`time` 包中有一些有趣的功能可以和通道组合使用。

其中就包含了 `time.Ticker` 结构体，这个对象以指定的时间间隔重复的向通道 C 发送时间值：

```go
type Ticker struct {
    C <-chan Time // the channel on which the ticks are delivered.
    // contains filtered or unexported fields
    ...
}
```

时间间隔的单位是 ns（纳秒，int64），在工厂函数 `time.NewTicker` 中以 `Duration` 类型的参数传入：`func Newticker(dur) *Ticker`。

在协程**周期性** 的执行一些事情（打印状态日志，输出，计算等等）的时候非常有用。

调用 `Stop()` 使计时器停止，在 `defer` 语句中使用。这些都很好的适应 `select` 语句:

```go
ticker := time.NewTicker(updateInterval)
defer ticker.Stop()
...
select {
case u:= <-ch1:
    ...
case v:= <-ch2:
    ...
case <-ticker.C:
    logState(status) // call some logging function logState
default: // no value ready to be received
    ...
}
```

time.Tick() 函数声明为 `Tick(d Duration) <-chan Time`，当你想返回一个通道而不必关闭它的时候这个函数非常有用：它以 d 为周期给返回的通道发送时间，d 是纳秒数。

**下边的代码可以限制处理频率：**

```go
import "time"

rate_per_sec := 10
var dur Duration = 1e9 / rate_per_sec
chRate := time.Tick(dur) // a tick every 1/10th of a second
for req := range requests {
    <- chRate // rate limit our Service.Method RPC calls
    go client.Call("Service.Method", req, ...)
}
```

这样只会按照指定频率处理请求：`chRate` 阻塞了更高的频率。每秒处理的频率可以根据机器负载（和 / 或）资源的情况而增加或减少。

**问题 14.1：扩展上边的代码，思考如何承载周期请求数的暴增（提示：使用带缓冲通道和计时器对象）。**

**思路：**

1. **带缓冲通道**：为了应对瞬时的流量高峰，可以使用一个带缓冲的通道，允许一定数量的请求被缓冲。如果缓冲区满了，新的请求将被丢弃或者阻塞，具体策略可以根据需求调整。
2. **周期性请求**：使用 `time.Tick` 来控制周期性请求的速率，确保请求不会超过设定的速率。
3. **控制并发**：为每个请求启动一个 goroutine 进行处理，保证高并发情况下请求不被阻塞。

```go
import (
	"time"
	"fmt"
)

func main() {
	// 设置请求速率：每秒 10 次
	rate_per_sec := 10
	var dur time.Duration = 1e9 / rate_per_sec

	// 设置一个带缓冲的通道用于存储请求
	bufferSize := 100
	requests := make(chan Request, bufferSize)

	// 启动一个定时器，用于控制请求的发放速率
	chRate := time.Tick(dur) // 每 1/10 秒一个 tick

	// 模拟发送请求的 goroutine
	go func() {
		for {
			req := Request{}  // 假设请求结构体
			select {
			case requests <- req:
				// 请求放入缓冲通道
			default:
				// 缓冲通道已满，丢弃请求或者采取其他策略
				fmt.Println("Request buffer full, discarding request")
			}
			time.Sleep(time.Second / 10) // 模拟请求产生的速率
		}
	}()

	// 启动一个 worker pool 来并发处理请求
	for req := range requests {
		// 控制请求速率，确保请求在合适的速率下处理
		<-chRate

		// 并发地处理每个请求
		go func(req Request) {
			// 调用服务方法
			// 假设 client.Call 实际调用的是 Service.Method
			err := client.Call("Service.Method", req, ...)
			if err != nil {
				// 处理请求错误
				fmt.Println("Request failed:", err)
			}
		}(req)
	}
}

// 假设有一个 Request 类型用于表示请求
type Request struct {
	// 请求的数据
}

// 假设有一个 client 类型，用于模拟 RPC 请求
var client struct {
	Call func(service, method string, req Request, args ...interface{}) error
}

```

定时器（Timer）结构体看上去和计时器（Ticker）结构体的确很像（构造为 NewTimer(d Duration)），但是它只发送一次时间，在 Dration d 之后。

还有 time.After(d) 函数，声明如下：

```go
func After(d Duration) <-chan Time
```

在 Duration d 之后，当前时间被发到返回的通道；所以它和 NewTimer(d).C 是等价的；它类似 Tick()，**但是 After() 只发送一次时间。下边有个很具体的示例，很好的阐明了 select 中 default 的作用.**

示例 14.11：[timer_goroutine.go](https://github.com/Unknwon/the-way-to-go_ZH_CN/blob/master/eBook/examples/chapter_14/timer_goroutine.go)：

```go
package main

import (
	"fmt"
	"time"
)

func main() {
	tick := time.Tick(1e8)
	boom := time.After(5e8)

	for {
		select {
		case <-tick:
			fmt.Println("tick.")
		case <-boom:
			fmt.Println("BOOM")
			return
		default:
			fmt.Println(" .")
			time.Sleep(5e7)
		}
	}
}

/*
    .
    .
tick.
    .
    .
tick.
    .
    .
tick.
    .
    .
tick.
    .
    .
tick.
BOOM!
*/
```

```php
Copy
```



#### **补充：习惯用法：简单超时模式**

**第一种形式：1s内没有接受到信号则取消**

要从通道 `ch` 中接收数据，但是最多等待 1 秒。先创建一个信号通道，然后启动一个 `lambda` 协程，协程在给通道发送数据之前是休眠的：

```go
timeout := make(chan bool, 1)
go func() {
        time.Sleep(1e9) // one second
        timeout <- true
}()
```

然后使用 `select` 语句接收 `ch` 或者 `timeout` 的数据：如果 `ch` 在 1 秒内没有收到数据，就选择到了 `time` 分支并放弃了 `ch` 的读取。

```go
select {
    case <-ch:
        // a read from ch has occured
    case <-timeout:
        // the read from ch has timed out
        break
}
```

**第二种形式：取消耗时很长的同步调用**

也可以使用 time.After() 函数替换 timeout-channel。可以在 select 中通过 time.After() 发送的超时信号来停止协程的执行。以下代码，在 timeoutNs 纳秒后执行 select 的 timeout 分支后，执行 client.Call 的协程也随之结束，不会给通道 ch 返回值：

```go
ch := make(chan error, 1)
go func() { ch <- client.Call("Service.Method", args, &reply) } ()
select {
case resp := <-ch
    // use resp and reply
case <-time.After(timeoutNs):
    // call timed out
    break
}
```

**注意缓冲大小设置为 1 是必要的**，可以避免协程死锁以及确保超时的通道可以被垃圾回收。

此外，需要注意在有多个 case 符合条件时， select 对 case 的选择是**伪随机**的，如果上面的代码稍作修改如下，则 select 语句可能不会在定时器超时信号到来时立刻选中 time.After(timeoutNs) 对应的 case，因此协程可能不会严格按照定时器设置的时间结束。

```go
ch := make(chan int, 1)
go func() { for { ch <- 1 } } ()
L:
for {
    select {
    case <-ch:
        // do something
    case <-time.After(timeoutNs):
        // call timed out
        break L
    }
}
```

**第三种形式：假设程序从多个复制的数据库同时读取。**

只需要一个答案，需要接收首先到达的答案，Query 函数获取数据库的连接切片并请求。并行请求每一个数据库并返回收到的第一个响应：

```go
func Query(conns []conn, query string) Result {
    ch := make(chan Result, 1)
    for _, conn := range conns {
        go func(c Conn) {
            select {
            case ch <- c.DoQuery(query):
            default:
            }
        }(conn)
    }
    return <- ch
}
```

**再次声明，结果通道 ch 必须是带缓冲的：以保证第一个发送进来的数据有地方可以存放，确保放入的首个数据总会成功，所以第一个到达的值会被获取而与执行的顺序无关。**

正在执行的协程可以总是可以使用 runtime.Goexit() 来停止。



### 6 协程和恢复（recover）

一个用到 `recover` 的程序（参见第 13.3 节）停掉了服务器内部一个失败的协程而不影响其他协程的工作。

```go
func server(workChan <-chan *Work) {
    for work := range workChan {
        go safelyDo(work)   // start the goroutine for that work
    }
}

func safelyDo(work *Work) {
    defer func() {
        if err := recover(); err != nil {
            log.Printf("Work failed with %s in %v", err, work)
        }
    }()
    do(work)
}
```

上边的代码，如果 `do(work)` 发生 panic，错误会被记录且协程会退出并释放，**而其他协程不受影响** 。

因为 recover 总是返回 nil，除非直接在 defer 修饰的函数中调用，defer 修饰的代码可以调用那些自身可以使用 panic 和 recover 避免失败的库例程（库函数）。

恢复是在 panicking 的协程内部的：不能被另外一个协程恢复。



### 7 新旧模型对比：任务和worker

假设我们需要处理很多任务；一个 worker 处理一项任务。

任务可以被定义为一个结构体（具体的细节在这里并不重要）：

```go
type Task struct {
    // some state
}
```

#### **旧模式：使用共享内存进行同步**

由各个任务组成的任务池共享内存；为了同步各个 worker 以及避免资源竞争，我们需要对任务池进行加锁保护：

```go
type Pool struct {
  Mu      sync.Mutex
  Tasks   []Task
}
```

sync.Mutex用来在代码中保护临界区资源：同一时间只有一个 go 协程（goroutine）可以进入该临界区。在传统的模式中（经典的面向对象的语言中)，**worker 代码可能这样写：**

```go
func Worker(pool *Pool) {
    for {
        pool.Mu.lock()
        // begin critical section:
        task := pool.Task[0]        // take the first task
        pool.Tasks = pool.Task[1:]  // update the pool of tasks
        // end critical section
        pool.Mu.Unlock()
        process(task)
    }
}
```

这些 worker 有许多都可以并发执行；他们可以在 go 协程中启动。

+ 一个 worker 先将 pool 锁定，从 pool 获取第一项任务，再解锁和处理任务。
+ 加锁保证了同一时间只有一个 go 协程可以进入到 pool 中：一项任务有且只能被赋予一个 worker。
+ 如果不加锁，则工作协程可能会在 task:=pool.Task[0] 发生切换，导致 pool.Tasks=pool.Task[1:] 结果异常：一些 worker 获取不到任务，而一些任务可能被多个 worker 得到。

加锁实现同步的方式在工作协程比较少时可以工作的很好，但是当工作协程数量很大，任务量也很多时，处理效率将会因为频繁的加锁 / 解锁开销而降低。**当工作协程数增加到一个阈值时，程序效率会急剧下降，这就成为了瓶颈。**

#### **新模式：使用通道**

使用通道进行同步：

+ 使用一个通道接受需要处理的任务
+ 一个通道接受处理完成的任务（及其结果）

worker 在协程中启动，其数量 N 应该根据任务数量进行调整。

主线程扮演着 Master 节点角色，可能写成如下形式：

```go
func main() {
    pending, done := make(chan *Task), make(chan *Task)
    go sendWork(pending)       // put tasks with work on the channel
    for i := 0; i < N; i++ {   // start N goroutines to do work
      	go Worker(pending, done)
    }
    consumeWork(done)          // continue with the processed tasks
}
```

worker 的逻辑比较简单：从 pending 通道拿任务，处理后将其放到 done 通道中：

```go
func Worker(in, out chan *Task) {
    for {
        t := <-in
        process(t)
        out <- t
    }
}
```

这里并不使用锁：从通道得到新任务的过程没有任何竞争。

+ 随着任务数量增加，worker 数量也应该相应增加，同时性能并不会像第一种方式那样下降明显。worker 数量的增多会增加通信的开销，这会对性能有轻微的影响。
+ 在 pending 通道中存在一份任务的拷贝，第一个 worker 从 pending 通道中获得第一个任务并进行处理，这里并不存在竞争（对一个通道读数据和写数据的整个过程是原子性的：参见 14.2.2)。
+ 某一个任务会在哪一个 worker 中被执行是不可知的，反过来也是。

**因此，第二种模式对比第一种模式而言，不仅性能是一个主要优势，而且还有个更大的优势：代码显得更清晰、更优雅。**

**一个更符合 go 语言习惯的 worker 写法：**

**IDIOM: Use an in- and out-channel instead of locking**

```go
func Worker(in, out chan *Task) {
    for {
        t := <-in
        process(t)
        out <- t
    }
}
```

对于任何可以建模为 Master-Worker 范例的问题，一个类似于 worker 使用通道进行通信和交互、Master 进行整体协调的方案都能完美解决。如果系统部署在多台机器上，各个机器上执行 Worker 协程，Master 和 Worker 之间可以使用 netchan 或者 RPC 进行通信（参见 15 章）。



#### 怎么选择是该使用锁还是通道？

 通道是一个较新的概念，go 语言让你可以根据实际问题进行选择：创建一个优雅、简单、可读性强、在大多数场景性能表现都能很好的方案。如果你的问题适合使用锁，也不要忌讳使用它。

go 语言注重实用，什么方式最能解决你的问题就用什么方式，而不是强迫你使用一种编码风格。下面列出一个普遍的经验法则：

- 使用锁的情景：
  - 访问共享数据结构中的缓存信息
  - 保存应用程序上下文和状态信息数据

- 使用通道的情景：
  - 与异步操作的结果进行交互
  - 分发任务
  - 传递数据所有权

当你发现你的锁使用规则变得很复杂时，可以反省使用通道会不会使问题变得简单些。



### 8 惰性生成器的实现

生成器是指当被调用时返回一个序列中下一个值的函数，例如：

```go
generateInteger() => 0
generateInteger() => 1
generateInteger() => 2
....
```

生成器每次返回的是序列中下一个值而非整个序列；这种特性也称之为惰性求值。

例如，生成一个无限数量的偶数序列：要产生这样一个序列并且在一个一个的使用可能会很困难，而且内存会溢出！但是一个含有通道和 go 协程的函数能轻易实现这个需求。

在 14.12 的例子中，我们实现了一个使用 int 型通道来实现的生成器。通道被命名为 `yield` 和 `resume`，这些词经常在协程代码中使用。**Listing 14.12-lazy evaluation.go**

```go
package main

import "fmt"

var resume chan int

func integers() chan int {
	yield := make(chan int)
	count := 0
	go func() {
		for {
			yield <- count
			count++
		}
	}()
	return yield
}

func generateInteger() int {
	return <-resume
}

func main() {
	resume = integers()
	fmt.Println(generateInteger()) //=> 0
	fmt.Println(generateInteger()) //=> 1
	fmt.Println(generateInteger()) //=> 2
}
```

有一个细微的区别是从通道读取的值可能会是稍早前产生的，并不是在程序被调用时生成的。如果确实需要这样的行为，就得实现一个请求响应机制。当生成器生成数据的过程是计算密集型且各个结果的顺序并不重要时，那么就可以将生成器放入到 go 协程实现并行化。

通过巧妙地使用空接口、闭包和高阶函数，我们能实现一个通用的惰性生产器的工厂函数 BuildLazyEvaluator（这个应该放在一个工具包中实现）。

+ 工厂函数需要一个函数和一个初始状态作为输入参数，返回一个无参、返回值是生成序列的函数。
+ 传入的函数需要计算出下一个返回值以及下一个状态参数。在工厂函数中，创建一个通道和无限循环的 go 协程。返回值被放到了该通道中，返回函数稍后被调用时从该通道中取得该返回值。
+ 每当取得一个值时，下一个值即被计算。

在下面的例子中，定义了一个 evenFunc 函数，其是一个惰性生成函数：在 main 函数中，我们创建了前 10 个偶数，每个都是通过调用 even() 函数取得下一个值的。**为此，我们需要在 BuildLazyIntEvaluator 函数中具体化我们的生成函数，然后我们能够基于此做出定义。**

**Listing 14.13: general lazy evaluation1.go**

```go
package main

import "fmt"

type Any interface{}
type EvalFunc func(Any) (Any, Any)

func BuildLazyEvaluator(evalFunc EvalFunc, initState Any) func() Any {
	retValChan := make(chan Any)
	loopFunc := func() {
		var actState Any = initState
		var retVal Any
		for {
			retVal, actState = evalFunc(actState)
			retValChan <- retVal
		}
	}
	retFunc := func() Any {
		return <-retValChan
	}
	go loopFunc()
	return retFunc
}

func BuildLazyIntEvaluator(evalFunc EvalFunc, initState Any) func() int {
	ef := BuildLazyEvaluator(evalFunc, initState)
	return func() int {
		return ef().(int)
	}
}

func main() {
	evenFunc := func(state Any) (Any, Any) {
		os := state.(int)
		ns := os + 2
		return os, ns
	}

	even := BuildLazyIntEvaluator(evenFunc, 0)
	for i := 0; i < 10; i++ {
		fmt.Printf("%vth even: %v\n", i, even())
	}
}

```

**练习 14.12：general_lazy_evaluation2.go**

**通过使用 14.12 中工厂函数生成前 10 个斐波那契数**

提示：因为斐波那契数增长很迅速，使用 uint64 类型。

```go
package main

import "fmt"

type Any interface{}
type Evaluator func(Any) (Any, Any)

func BuildLazyEvaluator(evaluator Evaluator, initState Any) func() Any {
	in := make(chan Any)
	loopFunc := func() {
		s := initState
		var res Any
		for {
			_, res = evaluator(s)
			s = Any(s.(uint) + 1)
			in <- res
		}
	}

	retFunc := func() Any {
		return <-in
	}
	go loopFunc()
	return retFunc
}

func BuildLazyIntEvaluator(evaluator Evaluator, initState Any) func() uint {
	ef := BuildLazyEvaluator(evaluator, initState)
	return func() uint {
		return ef().(uint)
	}
}

func fibonacci(k uint) uint {
	if k <= 1 {
		return 1
	} else {
		return fibonacci(k-1) + fibonacci(k-2)
	}
}

func main() {
	fiboFunc := func(state Any) (Any, Any) {
		s := state.(uint)
		return s, fibonacci(s)
	}

	fibonacci := BuildLazyIntEvaluator(fiboFunc, uint(0))
	for i := 0; i < 10; i++ {
		fmt.Printf("%vth fibonacci: %v\n", i, fibonacci())
	}
}

/*
0th fibonacci: 1
1th fibonacci: 1
2th fibonacci: 2
3th fibonacci: 3
4th fibonacci: 5
5th fibonacci: 8
6th fibonacci: 13
7th fibonacci: 21
8th fibonacci: 34
9th fibonacci: 55
*/
```

注：这种计算通常被定义为递归函数，但是在没有尾递归的语言中，例如 go 语言，这可能会导致栈溢出，但随着 go 语言中堆栈可扩展的优化，这个问题就不那么严重。这里使用的诀窍使用了惰性求值。gccgo 编译器在某些情况下会实现尾递归。





### 9  实现 Futures 模式

所谓 Futures 就是指：有时候在你使用某一个值之前需要先对其进行计算。这种情况下，你就可以在另一个处理器上进行该值的计算，到使用时，该值就已经计算完毕了。

**Futures 模式通过闭包和通道可以很容易实现，类似于生成器，不同地方在于 Futures 需要返回一个值。**

参考条目文献给出了一个很精彩的例子：假设我们有一个矩阵类型，我们需要计算两个矩阵 A 和 B 乘积的逆，首先我们通过函数 `Inverse(M)` 分别对其进行求逆运算，在将结果相乘。

**如下函数 `InverseProduct()` 实现了如上过程：**

```go
func InverseProduct(a Matrix, b Matrix) {
    a_inv := Inverse(a)
    b_inv := Inverse(b)
    return Product(a_inv, b_inv)
}
```

在这个例子中，a 和 b 的求逆矩阵需要先被计算。那么为什么在计算 b 的逆矩阵时，需要等待 a 的逆计算完成呢？显然不必要，这两个求逆运算其实可以并行执行的。

换句话说，**调用 Product 函数只需要等到 a_inv 和 b_inv 的计算完成** 。如下代码实现了并行计算方式

```go
func InverseProduct(a Matrix, b Matrix) {
    a_inv_future := InverseFuture(a)   // start as a goroutine
    b_inv_future := InverseFuture(b)   // start as a goroutine
    a_inv := <-a_inv_future
    b_inv := <-b_inv_future
    return Product(a_inv, b_inv)
}
```

InverseFuture 函数起了一个 goroutine 协程，在其执行闭包运算，该闭包会将矩阵**求逆结果放入到 future 通道中：**

```go
func InverseFuture(a Matrix) {
    future := make(chan Matrix)
  	// 异步API
    go func() {
        future <- Inverse(a)
    }()
    return future
}
```

**当开发一个计算密集型库时，使用 Futures 模式设计 API 接口是很有意义的。**

在你的包使用 Futures 模式，且能保持友好的 API 接口。此外，Futures 可以通过一个异步的 API 暴露出来。这样你可以以最小的成本将包中的并行计算移到用户代码中。



### 10 多路复用

#### 10.1 典型的客户端-服务端模式

**`Client-server` 类的应用是协程（goroutine）和频道（channel）的大显身手的闪光点。**

+ 客户端可以是任何一种运行在任何设备上的，且需要来自服务端信息的一种程序，所以它需要发送请求。
+  服务端接收请求，做一些处理，然后把给客户端发送响应信息。
+ 在通常情况下，就是多个客户端（很多请求）对一个（或几个）服务端。一个常见例子就是我们使用的发送网页请求的客户端浏览器。然后一个 web 服务器将响应网页发回给浏览器。

在 Go 中，服务端通常会在一个协程（goroutine）里操作对一个客户端的响应，所以协程和客户端请求是一一对应的。**一种典型的做法就是客户端请求本身包含了一个频道（channel），服务端可以用它来发送响应。**

**例如，一个请求结构体类似如下形式，内嵌了一个回复 channel：**

```go
type Request struct {

    a, b int;

    replyc chan int;

    // 请求内部的回复 channel 

}
```

或者更通常如下：

```go
type Reply struct { ... }

type Request struct {

    arg1, arg2, arg3 some_type

    replyc chan *Reply

}
```

继续上面的简单形式，服务端可以在一个 goroutine 里面为每个请求都分配一个 run () 函数，这个函数会把 binOp 类型的操作作用于整数，**然后通过回复 channel 发送结果：**

```go
type binOp func(a, b int) int

func run(op binOp, req *Request) {

    req.replyc <- op(req.a, req.b)

}
```

**服务端通过死循环来从 chan *Request 接收请求，为了避免长时间运行而导致阻塞，可以为每个请求都开一个 goroutine 来处理：**

```go
func server(op binOp, service chan *Request) {
    for {
        req := <-service; // requests arrive here

        // 为请求开一个 goroutine:

        go run(op, req);

        // 不用等待 op 结束
    }

}
```

使用 `startServer` 函数来启动服务的自有的协程（goroutine）：

```go
func startServer(op binOp) chan *Request {

    reqChan := make(chan *Request);

    go server(op, reqChan);

    return reqChan;

}
```

`startServer()` 将会在 `main()` 主线程里被调用。

**在下面的例子中，我们发送 100 个请求，并在所有请求发送完毕后，再逐个检查其返回的结果：**

```go
func main() {

    adder := startServer(func(a, b int) int { return a + b })

    const N = 100
    var reqs [N]Request
  
    for i := 0; i < N; i++ {
        req := &reqs[i]
        req.a = i
        req.b = i + N
        req.replyc = make(chan int)
        adder <- req
        // adder is a channel of requests
    }

    // checks:

    for i := N - 1; i >= 0; i-- { // doesn’t matter what order
        if <-reqs[i].replyc != N+2*i {
            fmt.Println(“fail at”, i)
            } else {
                fmt.Println(“Request “, i, “is ok!”)
        }
    }
    fmt.Println(“done”)
}

/*
Request 99 is ok!

Request 98 is ok!

…

Request 1 is ok!

Request 0 is ok!

Done
*/
```

这个程序只开启 100 个 Goroutines 。执行 100000 个 Goroutines 的程序，甚至可以看到它在几秒钟内完成。这说明了 Goroutines 是有多么的轻量：**如果我们启动相同数量的实际线程，程序将很快崩溃。**

#### 10.2 拆解：通过发信号通知关闭服务器

**在以前的版本中，服务器在主返回时并不会被干净的关闭；它被强制停止。**

为了改善这一点，我们可以向服务器提供第二个退出通道：

```go
func startServer(op binOp) (service chan *Request, quit chan bool) {

    service = make(chan *Request)

    quit = make(chan bool)

    go server(op, service, quit)

    return service, quit

}
```

`server` 函数使用 `select` 在服务通道和退出通道之间进行选择：

```go
func server(op binOp, service chan *Request, quit chan bool) {

    for {

        select {

            case req := <-service:

            go run(op, req)

            case <-quit:

            return
        }
    }
}
```

当 `真` 值进入退出通道时，服务器返回并终止。

主要我们改变下面一行：

```go
adder, quit := startServer(func(a, b int) int { return a + b })
```

在主要结尾处，我们放置该行：

```go
quit <- true
```

代码与10.1中具有相同的输出。

**练习 14.13：multiplex_server3.go：使用前面的例子，在 Request 结构中写入一个带有 String() 方法的变体，以便输出服务器；用 2 个请求测试程序：**

```go
req1 := &Request{3, 4, make(chan int)}

req2 := &Request{150, 250, make(chan int)}

…

// show the output:

fmt.Println(req1,"\n",req2)
```

代码如下：

```go
package main

import "fmt"

type Request struct {
	a, b   int
	replyc chan int // reply channel inside the Request
}

type binOp func(a, b int) int

func run(op binOp, req *Request) {
	req.replyc <- op(req.a, req.b)
}

func (r *Request) String() string {
	return fmt.Sprintf("%d + %d = %d", r.a, r.b, <-r.replyc)
}

func server(op binOp, service chan *Request, quit chan bool) {
	for {
		select {
		case req := <-service:
			go run(op, req)
		case <-quit:
			return
		}
	}
}

func startServer(op binOp) (service chan *Request, quit chan bool) {
	service = make(chan *Request)
	quit = make(chan bool)
	go server(op, service, quit)
	return service, quit
}

func main() {
	adder, quit := startServer(func(a, b int) int { return a + b })

	// make requests:
	req1 := &Request{3, 4, make(chan int)}
	req2 := &Request{150, 250, make(chan int)}

	// send requests on the service channel
	adder <- req1
	adder <- req2
	
	// ask for the results: ( method String() is called )
	fmt.Println(req1, req2)
	// shutdown server:
	quit <- true
	fmt.Print("done")
}

/*
3+4=7 150+250=400
done
*/
```



### 11 限制并发数

**可以很轻松的实现一个带缓冲的通道 ，它的容量是并发请求的最大数目。**

下面的示例 max_tasks.go 没做任何事情，它包含了下列技巧：

+ **不超过 MAXREQS 的请求将被处理并且是同时处理**
  + 因为当通道 sem 的缓冲区全被占用时，函数 handle 被阻塞，直到缓冲区中的请求被执行完成并且从 sem 中删除之前，不能执行其他的请求。
  + sem 就像一个 semaphore （信号量）

**Listing 14.16—max_tasks.go：**

```go
package main

const (
	// AvailableMemory 10 MB
	AvailableMemory = 10 << 20

	// AverageMemoryPerRequest 10 KB
	AverageMemoryPerRequest = 10 << 10

	MAXREQS = AvailableMemory / AverageMemoryPerRequest
)

var sem = make(chan int, MAXREQS)

type Request struct {
	a, b   int
	replyc chan int
}

func process(r *Request) {
	// Do something 做任何事

	// 可能需要很长时间并使用大量内存或CPU
}

func handle(r *Request) {
	process(r)
	// 信号完成：开始启用下一个请求
	// 将 sem 的缓冲区释放一个位置
	<-sem
}

func Server(queue chan *Request) {
	for {
		sem <- 1
		// 当通道已满（1000 个请求被激活）的时候将被阻塞
		request := <-queue
		go handle(request)
	}
}

func mainMaxTasks() {
	queue := make(chan *Request)
	go Server(queue)
}

```

**通过这种方式，程序中的协程通过使用缓冲通道（这个通道作为一个 semaphore 被使用）来调整资源的使用，实现了对内存等有限资源的优化。**



### 12 链式操作

下面的演示程序 chaining.go 再次演示了启动大量的协程是多么的容易。它发生在 main 函数的 for 循环中。

**在循环之后，向 rightmost 通道中插入 0 ，在不到 1.5 s 的时间执行了 100000 个协程，并将结果 100000 打印。**

这个程序还演示了如何通过命令行的参数定义一个协程的数量，并通过 flag.Int 解析，例如： chaining -n=7000 （编译后通过命令行执行），可以生成 7000 个协程。

示例 14.17 - chaining.go：

```go
package main

import (
    "flag"
    "fmt"
)

var ngoroutine = flag.Int("n", 100000, "how many goroutines")

// last 相当于上一个的意思
func f(last, current chan int) {
    temp := 1 + <-current // 当 current 没有值时,这里会被阻塞
    last <- temp
}

func main() {
    first := make(chan int)

    last := first
    for i := 0; i < *ngoroutine; i++ {
        current := make(chan int)

        // 将上一次循环创建的 chan,和本次循环的 chan 一起交给函数, 函数会帮我们完成 last <- 1+ <- curr 的过程
        go f(last, current)

        // 记录本次循环中的 right,给下一次循环创建使用
        last = current
    }

    // 开始链接
    last <- 0

    x := <-first // wait for completion 等待完成

    fmt.Println(x)
    // 结果： 100000 ， 大约 1,5s （我实际测试只用了不到200ms）
}
```



### 13 多核运算

假设我们的 CPU 核数是 NCPU 个： const NCPU = 4 // 例如：4 代表 4 核处理器

**我们将计算划分为 NCPU 部分，每部分与其他部分并行运行。**

下面是一个简单的示例（我们忽略具体的参数）：

```go
func DoAll() {

    sem := make(chan int, NCPU)

    for i := 0; i < NCPU; i++ {
        // Buffering optional but sensible. 合理的缓冲区选项（个人理解就是和 CPU 的核心数相同）
        go DoPart(sem)
    }

    // 等待 NCPU 任务完成，释放通道 sem 的缓冲区

    for i := 0; i < NCPU; i++ {
        <-sem // 等待一个任务完成
    }

    // 全部完成。
}

func DoPart(sem chan int) {
    // 进行计算的部分
    ...
    sem <- 1 // 发送一个这部分已经完成的信号，用来释放 sem 的缓冲区
}

func main() {
    runtime.GOMAXPROCS = NCPU
    DoAll()
}
```

+ 函数 DoAll() 生成一个通道 sem ，在此基础上完成每一个并行计算；
  + 在 for 循环中启动 NCPU 个协程，每一个协程执行全部工作的 1/NCPU 。
  + 通过 sem 发送每一个协程中 DoPart() 完成的信号。
+ DoAll() 中用一个 for 循环来等待所有 （NCPU 个）协程完成计算： 
  + 通道 sem 的行为就像一个 semaphore（信号量） ；
  + 这个代码展示了一个典型的 信号量模式（可以参见 14.2.7 章节）

在当前的运行模式下，你还必须设置 GOMAXPROCS 为 NCPU（可以参见 14.1.3）



### 14 多核运算处理大量数据

**假设我们必须处理大量的彼此独立的数据项，通过一个输入通道进入，并且全部处理完成后放到一个输出通道，就像一个工厂的管道。**

每个数据项的处理也许会涉及多个步骤： 预处理 / 步骤 A / 步骤 B / … / 后期处理

**一个典型的顺序 流水线算法 可以用来解决这个问题，下面示例展示了每一步执行的顺序：**

```go
func SerialProcessData (in <- chan *Data, out <- chan *Data) {
    for data := range in {
        tmpA := PreprocessData(data)
        tmpB := ProcessStepA(tmpA)
        tmpC := ProcessStepB(tmpB)
        out <- PostProcessData(tmpC)
    }
}
```

一次只执行一步，并且每个项目按顺序处理：在第一个项目被处理完并将结果放到输出通道之前第二个项目不会开始。

如果你仔细想想，你很快就会意识到这样会非常的浪费时间。

**一个更有效的计算是让每一个步骤都作为一个协程独立工作。每个步骤都从上一步的输出通道获取输入数据。这样可以尽可能的避免时间浪费，并且大部分时间所有的步骤都会繁忙的执行：**

```go
func ParallelProcessData (in <- chan *Data, out <- chan *Data) {

    // make channels:
    preOut := make(chan *Data, 100)
    stepAOut := make(chan *Data, 100)
    stepBOut := make(chan *Data, 100)
    stepCOut := make(chan *Data, 100)

    // start parallel computations:
    go PreprocessData(in, preOut)
    go ProcessStepA(preOut, stepAOut)
    go ProcessStepB(stepAOut, stepBOut)
    go ProcessStepC(stepBOut, stepCOut)
    go PostProcessData(stepCOut, out)
}
```

通道缓冲区可以用于进一步优化整个过程。



### 15 漏桶算法 Leaky Bucket

思考下面这个 client-server 配置： 客户端无限循环执行从某个来源（可能是来自网络）接收的数据；

+ 数据使用一个 Buffer 类型的缓冲区读取。
+ 为了避免过多的分配和释放 buffers，可以保留一个用缓冲通道表示的空闲列表： `var freeList = make(chan *Buffer, 100)`

**这个可以重复使用的缓冲队列与服务器端共享。**

+ 当客户端接收数据时，会尝试先从 freeList 获取一个 buffer ；
+ 如果 freeList 这个通道是空的，就分配一个新的 buffer。
+ 当这个 buffer 被加载完，它会通过 `serverChan` 发送给服务器端: 

```go
var serverChan = make(chan *Buffer)
```

下面是客户端代码的算法：

```go
func client() {

    for {

    var b *Buffer

    // 如果 freeList 通道中有 buffer，直接获取；如果没有，就创建一个新的

    select {

        case b = <-freeList:

        // 获取到一个 ，没有做其他事情

        default:

        // 没有空闲的，所以分配一个新的

        b = new(Buffer)

    }

    loadInto(b) // 从网络去获取下一条信息

    serverChan <- b // 发送给服务器端

    }

}
```

服务器端循环接收每一个客户端的消息，处理它，并尝试将 buffer 返回给共享的 buffers 列表：

```go
func server() {

    for {

        b := <-serverChan   // 等待工作。（等待客户端发送一个 buffer 过来）

        process(b)

        // 如果就空间，就重用 buffer

        select {

            case freeList <- b:

                // 如果 freeList 有空闲的插槽，就重用 buffer；没有做其他事情

            default:

                // freeList 已满，只是继续： 会将 buffer 掉落（丢弃） 

        }

    }

}
```

**但是当 freeList 已满时它不能工作，这种情况下的缓冲区是： `掉落到地上` （因此命名 `漏桶算法` ）被垃圾回收器回收。**



### 16 标杆分析 Goroutines

在 §13.7 章节，我们提到了 Go 函数中的性能基准测试原则。 在此我们将它应用于一个具体的范例之中：使用一个 goroutine 填充整数，然后再读取。测试中函数将被调用 N 次 (e.g. N = 1000000) 。

+ 基准测试中， BenchMarkResult 有一个 String () 方法用于输出结果。
+ 数值 N 由 gotest 决定，该值只有足够大才能判断出基准测试结果可靠合理。基准测试同样适用于普通函数。
+ **如果想排除一部分代码或者更具体的测算时间，你可以适当使用 testing.B.StopTimer() 和 testing.B.StartTimer() 来关闭或者启动计时器。只有所有测试全部通过，基准测试才会运行。**

**清单 14.18—benchmark_channels.go：**

```go
package main

import (
	"fmt"
	"testing"
)

func BenchmarkChannelSync(b *testing.B) {
	ch := make(chan int)
	go func() {
		for i := 0; i < b.N; i++ {
			ch <- i
		}
		close(ch)
	}()
	for range ch {
	}
}

func BenchmarkChannelBuffered(b *testing.B) {
	ch := make(chan int, 128)
	go func() {
		for i := 0; i < b.N; i++ {
			ch <- i
		}
		close(ch)
	}()
	for range ch {
	}
}

func main() {
	fmt.Println(" sync", testing.Benchmark(BenchmarkChannelSync).String())
	fmt.Println("buffered", testing.Benchmark(BenchmarkChannelBuffered).String())
}

/*
 sync  5399154         223.9 ns/op
buffered 18333240               65.58 ns/op

*/
```



### 17 使用 Channel 来并发读取对象

**为了保护一个对象的并发修改，我们可以使用一个后台的协程来顺序执行一个匿名函数，而不是通过同步 `互斥锁（Mutex）` 进行锁定。**

+ 在下面的程序中，我们有一个 Person 类型，它包含了一个匿名函数类型的通道字段 chF。它在构造器方法 NewPerson 中初始化，用一个协程启动一个 `backend()` 方法。
+ 这个方法在一个无限 for 循环中执行所有被放到 chF 上的函数，有效的序列化他们，从而提供安全的并发访问。
+ **改变和获取 salary 可以通过一个放在 chF 上的匿名函数来实现，`backend()` 会顺序执行它们。**
+ **注意如何在 Salary 方法中的闭合（匿名）函数中去包含 `fChan` 通道。**

这是一个简化的例子，并且它不应该在这种情况下应用，但是它展示了如何在更复杂的情况下解决问题。

**示例 14.19—conc_access.go：**

```go
package main

import (
	"fmt"
	"strconv"
)

type Person struct {
	Name   string
	salary float64
	chF    chan func()
}

func newPerson(name string, salary float64) *Person {
	p := &Person{name, salary, make(chan func())}
	go p.backend()
	return p
}

func (p *Person) backend() {
	for f := range p.chF {
		f()
	}
}

// SetSalary set salary
func (p *Person) SetSalary(sal float64) {
	p.chF <- func() {
		p.salary = sal
	}
}

// Salary get salary
func (p *Person) Salary() float64 {
	fChan := make(chan float64)
	p.chF <- func() { fChan <- p.salary }
	return <-fChan
}

func (p *Person) String() string {
	return "Person - name is: " + p.Name + " - salary is: " +
		strconv.FormatFloat(p.Salary(), 'f', 2, 64)
}

func main() {
	bs := newPerson("Smith Bill", 2500.5)
	fmt.Println(bs)

	bs.SetSalary(4000.25)
	fmt.Println("Salary changed:")
	fmt.Println(bs)
}


/*
Person - name is: Smith Bill - salary is: 2500.50
Salary changed:
Person - name is: Smith Bill - salary is: 4000.25
*/
```

